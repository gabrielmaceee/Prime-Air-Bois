print(paste("Recall = ", vp_usage / (vp_usage + fn_usage)))
print(paste("Recall = ", vp_usage / (vp_usage + fp_usage)))
res_usage <- table(predict(arbre_usage, newdata = test[, c(usage, "cluster_ind")], type = "class"), test$cluster_ind)
res_usage
fp_usage <- res_usage[2,1]
vp_usage <- res_usage[1,1]
fn_usage <- res_usage[1,2]
vn_usage <- res_usage[2,2]
print(paste("Accuracy = ", (vn_usage + vp_usage) / dim(test)[1] ))
print(paste("Recall = ", vp_usage / (vp_usage + fn_usage)))
print(paste("Recall = ", vp_usage / (vp_usage + fp_usage)))
res_sc = table(predict(arbre_sp, newdata = test[, c(socio_pro, "cluster_ind")], type = "class"), test$cluster_ind)
fp_sc <- res_sc[2,1]
vp_sc <- res_sc[1,1]
fn_sc <- res_sc[1,2]
vn_sc <- res_sc[2,2]
print(paste("Accuracy = ", (vn_sc + vp_sc) / dim(test)[1] ))
print(paste("Recall = ", vp_sc / (vp_sc + fn_sc)))
print(paste("Recall = ", vp_sc / (vp_sc + fp_sc)))
res_sc = table(predict(arbre_sp, newdata = test[, c(socio_pro, "cluster_ind")], type = "class"), test$cluster_ind)
res_sc
fp_sc <- res_sc[2,1]
vp_sc <- res_sc[1,1]
fn_sc <- res_sc[1,2]
vn_sc <- res_sc[2,2]
print(paste("Accuracy = ", (vn_sc + vp_sc) / dim(test)[1] ))
print(paste("Recall = ", vp_sc / (vp_sc + fn_sc)))
print(paste("Recall = ", vp_sc / (vp_sc + fp_sc)))
arbre_sp = rpart(cluster_ind~., data = train[ , c(socio_pro, "cluster_ind")],control = ("maxdepth = 1") )
rpart.plot(arbre_sp)
arbre_sp = rpart(cluster_ind~., data = train[ , c(socio_pro, "cluster_ind")], control = list(maxdepth = 1))
rpart.plot(arbre_sp)
arbre_sp = rpart(cluster_ind~., data = train[ , c(socio_pro, "cluster_ind")], control = list(maxdepth = 10))
rpart.plot(arbre_sp)
arbre_sp = rpart(cluster_ind~., data = train[ , c(socio_pro, "cluster_ind")], control = list(maxdepth = 100))
rpart.plot(arbre_sp)
res_usage <- table(predict(arbre_usage, newdata = test[, c(usage, "cluster_ind")], type = "class"), test$cluster_ind)
res_usage
fp_usage <- res_usage[2,1]
vp_usage <- res_usage[1,1]
fn_usage <- res_usage[1,2]
vn_usage <- res_usage[2,2]
print(paste("Accuracy = ", (vn_usage + vp_usage) / dim(test)[1] ))
print(paste("Recall = ", vp_usage / (vp_usage + fn_usage)))
print(paste("Precision = ", vp_usage / (vp_usage + fp_usage)))
arbre_sp = rpart(cluster_ind~., data = train[ , c(socio_pro, "cluster_ind")], control = list(cp = 0, maxdepth = 100))
rpart.plot(arbre_sp)
arbre_sp = rpart(cluster_ind~., data = train[ , c(socio_pro, "cluster_ind")], control = list(cp = 0, maxdepth = 10))
rpart.plot(arbre_sp)
res_sc = table(predict(arbre_sp, newdata = test[, c(socio_pro, "cluster_ind")], type = "class"), test$cluster_ind)
res_sc
fp_sc <- res_sc[2,1]
vp_sc <- res_sc[1,1]
fn_sc <- res_sc[1,2]
vn_sc <- res_sc[2,2]
print(paste("Accuracy = ", (vn_sc + vp_sc) / dim(test)[1] ))
print(paste("Recall = ", vp_sc / (vp_sc + fn_sc)))
print(paste("Precision = ", vp_sc / (vp_sc + fp_sc)))
arbre_sp = rpart(cluster_ind~., data = train[ , c(socio_pro, "cluster_ind")], control = list(cp = 0, maxdepth = 5))
rpart.plot(arbre_sp)
res_sc = table(predict(arbre_sp, newdata = test[, c(socio_pro, "cluster_ind")], type = "class"), test$cluster_ind)
res_sc
fp_sc <- res_sc[2,1]
vp_sc <- res_sc[1,1]
fn_sc <- res_sc[1,2]
vn_sc <- res_sc[2,2]
print(paste("Accuracy = ", (vn_sc + vp_sc) / dim(test)[1] ))
print(paste("Recall = ", vp_sc / (vp_sc + fn_sc)))
print(paste("Precision = ", vp_sc / (vp_sc + fp_sc)))
arbre_usage = rpart(cluster_ind~., data = train[ , c(usage, "cluster_ind")], control = list(cp = 0, maxdepth = 5))
rpart.plot(arbre_usage)
res_usage <- table(predict(arbre_usage, newdata = test[, c(usage, "cluster_ind")], type = "class"), test$cluster_ind)
res_usage
fp_usage <- res_usage[2,1]
vp_usage <- res_usage[1,1]
fn_usage <- res_usage[1,2]
vn_usage <- res_usage[2,2]
print(paste("Accuracy = ", (vn_usage + vp_usage) / dim(test)[1] ))
print(paste("Recall = ", vp_usage / (vp_usage + fn_usage)))
print(paste("Precision = ", vp_usage / (vp_usage + fp_usage)))
arbre_usage = rpart(cluster_ind~., data = train[ , c(usage, "cluster_ind")], control = list(cp = 0, maxdepth = 3))
rpart.plot(arbre_usage)
res_usage <- table(predict(arbre_usage, newdata = test[, c(usage, "cluster_ind")], type = "class"), test$cluster_ind)
res_usage
fp_usage <- res_usage[2,1]
vp_usage <- res_usage[1,1]
fn_usage <- res_usage[1,2]
vn_usage <- res_usage[2,2]
print(paste("Accuracy = ", (vn_usage + vp_usage) / dim(test)[1] ))
print(paste("Recall = ", vp_usage / (vp_usage + fn_usage)))
print(paste("Precision = ", vp_usage / (vp_usage + fp_usage)))
arbre_sp = rpart(cluster_ind~., data = train[ , c(socio_pro, "cluster_ind")], control = list(cp = 0, maxdepth = 3))
rpart.plot(arbre_sp)
res_sc = table(predict(arbre_sp, newdata = test[, c(socio_pro, "cluster_ind")], type = "class"), test$cluster_ind)
res_sc
fp_sc <- res_sc[2,1]
vp_sc <- res_sc[1,1]
fn_sc <- res_sc[1,2]
vn_sc <- res_sc[2,2]
print(paste("Accuracy = ", (vn_sc + vp_sc) / dim(test)[1] ))
print(paste("Recall = ", vp_sc / (vp_sc + fn_sc)))
print(paste("Precision = ", vp_sc / (vp_sc + fp_sc)))
arbre_sp = rpart(cluster_ind~., data = train[ , c(socio_pro, "cluster_ind")], control = list(cp = 0, maxdepth = 4))
rpart.plot(arbre_sp)
res_sc = table(predict(arbre_sp, newdata = test[, c(socio_pro, "cluster_ind")], type = "class"), test$cluster_ind)
res_sc
fp_sc <- res_sc[2,1]
vp_sc <- res_sc[1,1]
fn_sc <- res_sc[1,2]
vn_sc <- res_sc[2,2]
print(paste("Accuracy = ", (vn_sc + vp_sc) / dim(test)[1] ))
print(paste("Recall = ", vp_sc / (vp_sc + fn_sc)))
print(paste("Precision = ", vp_sc / (vp_sc + fp_sc)))
arbre_sp = rpart(cluster_ind~., data = train[ , c(socio_pro, "cluster_ind")], control = list(cp = 0, maxdepth = 3))
rpart.plot(arbre_sp)
res_sc = table(predict(arbre_sp, newdata = test[, c(socio_pro, "cluster_ind")], type = "class"), test$cluster_ind)
res_sc
fp_sc <- res_sc[2,1]
vp_sc <- res_sc[1,1]
fn_sc <- res_sc[1,2]
vn_sc <- res_sc[2,2]
print(paste("Accuracy = ", (vn_sc + vp_sc) / dim(test)[1] ))
print(paste("Recall = ", vp_sc / (vp_sc + fn_sc)))
print(paste("Precision = ", vp_sc / (vp_sc + fp_sc)))
set.seed(3)
cv_tree = cv.tree(arbre_sp, FUN = prune.misclass)
install.packages("ISLR")
install.packages("tree")
library(ISLR)
library(tree)
set.seed(3)
cv_tree = cv.tree(arbre_sp, FUN = prune.misclass)
set.seed(3)
cv_tree = cv.tree(tree(cluster_ind~., data = train[ , c(socio_pro, "cluster_ind")]), FUN = prune.misclass)
set.seed(3)
cv_tree = cv.tree(tree(cluster_ind~., data = train[ , c(socio_pro, "cluster_ind")], method = "class"), FUN = prune.misclass)
set.seed(3)
cv_tree = cv.tree(tree(cluster_ind~., train[ , c(socio_pro, "cluster_ind")], ), FUN = prune.misclass)
tree(cluster_ind~., train[ , c(socio_pro, "cluster_ind")])
set.seed(3)
cv_tree = cv.tree(tree(cluster_ind~., train[ , c(socio_pro, "cluster_ind")],  type = "class"), FUN = prune.misclass)
?tree
set.seed(3)
cv_tree = cv.tree(tree(as.character(cluster_ind)~., train[ , c(socio_pro, "cluster_ind")],  type = "class"), FUN = prune.misclass)
set.seed(3)
cv_tree = cv.tree(tree(as.character(cluster_ind)~., train[ , c(socio_pro, "cluster_ind")]), FUN = prune.misclass)
tree(as.character(cluster_ind)~., train[ , c(socio_pro, "cluster_ind")])
model = tree(as.character(cluster_ind)~., train[ , c(socio_pro, "cluster_ind")])
model$y
cv_tree = cv.tree(model, FUN = prune.misclass)
cv_tree = cv.tree(model)
set.seed(3)
model = tree(as.character(cluster_ind)~., train[ , c(socio_pro, "cluster_ind")])
cv_tree = cv.tree(model)
names(cv_tree)
# [1] "size" "dev" "k" "method"
# size of prune trees
# dev - deviance or cv error rate
# plot the size and deviance to see where error is lowest
plot(cv_tree$size, cv_tree$dev, type="b",
xlab='Tree Size',
ylab='Error Rate',
main = 'Cross Validation: Error Vs Size')
set.seed(3)
model = tree(cluster_ind~., train[ , c(socio_pro, "cluster_ind")])
cv_tree = cv.tree(model)
names(cv_tree)
# [1] "size" "dev" "k" "method"
# size of prune trees
# dev - deviance or cv error rate
# plot the size and deviance to see where error is lowest
plot(cv_tree$size, cv_tree$dev, type="b",
xlab='Tree Size',
ylab='Error Rate',
main = 'Cross Validation: Error Vs Size')
set.seed(3)
model = tree(cluster_ind~., train[ , c(socio_pro, "cluster_ind")])
cv_tree = cv.tree(model, K = 10)
names(cv_tree)
# [1] "size" "dev" "k" "method"
# size of prune trees
# dev - deviance or cv error rate
# plot the size and deviance to see where error is lowest
plot(cv_tree$size, cv_tree$dev, type="b",
xlab='Tree Size',
ylab='Error Rate',
main = 'Cross Validation: Error Vs Size')
install.packages("caret")
library(caret)
train_control <- trainControl(method = "cv", number = 10)
model <- train(cluster_ind~.,
data = train[ , c(socio_pro, "cluster_ind")],
method = "rpart",
trControl = train_control,
tuneGrid = expand.grid(cp = 0))
train_clean <- na.omit(train[ , c(socio_pro, "cluster_ind")])
train_clean <- na.omit(train[ , c(socio_pro, "cluster_ind")])
train_control <- trainControl(method = "cv", number = 10)
model <- train(cluster_ind~.,
data = train_clean,
method = "rpart",
trControl = train_control,
tuneGrid = expand.grid(cp = 0))
print(model)
train_clean <- na.omit(train[ , c(socio_pro, "cluster_ind")])
tune_grid <- expand.grid(cp = seq(0.001, 0.05, by = 0.005),
maxdepth = c(2, 3, 4, 5, 6))
custom_rpart <- function(x, y, cp, maxdepth) {
rpart(x = x, y = y, control = rpart.control(cp = cp, maxdepth = maxdepth))
}
model <- train(cluster_ind~.,
data = train_clean,
method = custom_rpart,
trControl = train_control,
tuneGrid = tune_grid)
train_clean <- na.omit(train[ , c(socio_pro, "cluster_ind")])
train_control <- trainControl(method = "cv", number = 10)
tune_grid <- expand.grid(cp = seq(0.001, 0.05, by = 0.005),
maxdepth = c(2, 3, 4, 5, 6))
custom_rpart <- function(x, y, cp, maxdepth) {
rpart(x = x, y = y, control = rpart.control(cp = cp, maxdepth = maxdepth))
}
model <- train(cluster_ind~.,
data = train_clean,
method = custom_rpart,
trControl = train_control,
tuneGrid = tune_grid)
train_clean <- na.omit(train[ , c(socio_pro, "cluster_ind")])
train_control <- trainControl(method = "cv", number = 10)
tune_grid <- expand.grid(cp = seq(0.001, 0.05, by = 0.005),
maxdepth = c(2, 3, 4, 5, 6))
results <- data.frame(cp = numeric(), maxdepth = numeric(), Accuracy = numeric())
for (cp in cp_values) {
for (maxdepth in maxdepth_values) {
# Entraîner le modèle
model <- rpart(cluster_ind~.,
data = train_clean,
control = rpart.control(cp = cp, maxdepth = maxdepth))
# Prédire sur les données d'entraînement (ou validation croisée si disponible)
predictions <- predict(model, train_clean, type = "class")
# Calculer la précision (ou une autre métrique)
accuracy <- sum(predictions == train_clean$cluster_ind) / nrow(train_clean)
# Stocker les résultats
results <- rbind(results, data.frame(cp = cp, maxdepth = maxdepth, Accuracy = accuracy))
}
}
train_clean <- na.omit(train[ , c(socio_pro, "cluster_ind")])
train_control <- trainControl(method = "cv", number = 10)
cp_values <- seq(0.001, 0.05, by = 0.005)
maxdepth_values <- c(2, 3, 4, 5, 6)
results <- data.frame(cp = numeric(), maxdepth = numeric(), Accuracy = numeric())
for (cp in cp_values) {
for (maxdepth in maxdepth_values) {
# Entraîner le modèle
model <- rpart(cluster_ind~.,
data = train_clean,
control = rpart.control(cp = cp, maxdepth = maxdepth))
# Prédire sur les données d'entraînement (ou validation croisée si disponible)
predictions <- predict(model, train_clean, type = "class")
# Calculer la précision (ou une autre métrique)
accuracy <- sum(predictions == train_clean$cluster_ind) / nrow(train_clean)
# Stocker les résultats
results <- rbind(results, data.frame(cp = cp, maxdepth = maxdepth, Accuracy = accuracy))
}
}
best_result <- results[which.max(results$Accuracy), ]
print(best_result)
train_clean <- na.omit(train[ , c(socio_pro, "cluster_ind")])
train_control <- trainControl(method = "cv", number = 10)
cp_values <- seq(0.001, 0.05, by = 0.005)
maxdepth_values <- c(2, 3, 4, 5, 6)
results <- data.frame(cp = numeric(), maxdepth = numeric(), Accuracy = numeric())
criteria <- c("gini", "information")
for (criterion in criteria) {
for (cp in cp_values) {
for (maxdepth in maxdepth_values) {
# Entraîner le modèle
model <- rpart(cluster_ind~.,
data = train_clean,
parms = list(split = criterion),
control = rpart.control(cp = cp, maxdepth = maxdepth))
# Prédire sur les données d'entraînement (ou validation croisée si disponible)
predictions <- predict(model, train_clean, type = "class")
# Calculer la précision (ou une autre métrique)
accuracy <- sum(predictions == train_clean$cluster_ind) / nrow(train_clean)
# Stocker les résultats
results <- rbind(results, data.frame(cp = cp, maxdepth = maxdepth, criterion = criterion, Accuracy = accuracy))
}
}
best_result <- results[which.max(results$Accuracy), ]
print(best_result)
train_clean <- na.omit(train[ , c(socio_pro, "cluster_ind")])
train_control <- trainControl(method = "cv", number = 10)
cp_values <- seq(0.001, 0.05, by = 0.005)
maxdepth_values <- c(2, 3, 4, 5, 6)
results <- data.frame(cp = numeric(), maxdepth = numeric(), Accuracy = numeric())
criteria <- c("gini", "information")
for (criterion in criteria) {
for (cp in cp_values) {
for (maxdepth in maxdepth_values) {
# Entraîner le modèle
model <- rpart(cluster_ind~.,
data = train_clean,
parms = list(split = criterion),
control = rpart.control(cp = cp, maxdepth = maxdepth))
# Prédire sur les données d'entraînement (ou validation croisée si disponible)
predictions <- predict(model, train_clean, type = "class")
# Calculer la précision (ou une autre métrique)
accuracy <- sum(predictions == train_clean$cluster_ind) / nrow(train_clean)
# Stocker les résultats
results <- rbind(results, data.frame(cp = cp, maxdepth = maxdepth, criterion = criterion, Accuracy = accuracy))
}
}
}
best_result <- results[which.max(results$Accuracy), ]
print(best_result)
train_clean <- na.omit(train[ , c(usage, "cluster_ind")])
train_control <- trainControl(method = "cv", number = 10)
cp_values <- seq(0.001, 0.05, by = 0.005)
maxdepth_values <- c(2, 3, 4, 5, 6)
results <- data.frame(cp = numeric(), maxdepth = numeric(), Accuracy = numeric())
criteria <- c("gini", "information")
for (criterion in criteria) {
for (cp in cp_values) {
for (maxdepth in maxdepth_values) {
# Entraîner le modèle
model <- rpart(cluster_ind~.,
data = train_clean,
parms = list(split = criterion),
control = rpart.control(cp = cp, maxdepth = maxdepth))
# Prédire sur les données d'entraînement (ou validation croisée si disponible)
predictions <- predict(model, train_clean, type = "class")
# Calculer la précision (ou une autre métrique)
accuracy <- sum(predictions == train_clean$cluster_ind) / nrow(train_clean)
# Stocker les résultats
results <- rbind(results, data.frame(cp = cp, maxdepth = maxdepth, criterion = criterion, Accuracy = accuracy))
}
}
}
best_result <- results[which.max(results$Accuracy), ]
print(best_result)
train_clean <- na.omit(train[ , c(usage, "cluster_ind")])
train_control <- trainControl(method = "cv", number = 10)
cp_values <- seq(0.001, 0.05, by = 0.005)
maxdepth_values <- c(2, 3, 4, 5, 6)
results <- data.frame(cp = numeric(), maxdepth = numeric(), Accuracy = numeric())
criteria <- c("gini", "information")
for (criterion in criteria) {
for (cp in cp_values) {
for (maxdepth in maxdepth_values) {
# Entraîner le modèle
model <- rpart(cluster_ind~.,
data = train_clean,
parms = list(split = criterion),
control = rpart.control(cp = cp, maxdepth = maxdepth))
# Prédire sur les données d'entraînement (ou validation croisée si disponible)
predictions <- predict(model, train_clean, type = "class")
# Calculer la précision (ou une autre métrique)
accuracy <- sum(predictions == train_clean$cluster_ind) / nrow(train_clean)
# Stocker les résultats
results <- rbind(results, data.frame(cp = cp, maxdepth = maxdepth, criterion = criterion, Accuracy = accuracy))
}
}
}
best_result <- results[which.max(results$Accuracy), ]
print(best_result)
arbre_usage = rpart(cluster_ind~., data = train[ , c(usage, "cluster_ind")], parms = list(split = criterion), control = list(cp = 0.01, maxdepth = 6))
rpart.plot(arbre_usage)
res_usage <- table(predict(arbre_usage, newdata = test[, c(usage, "cluster_ind")], type = "class"), test$cluster_ind)
res_usage
fp_usage <- res_usage[2,1]
vp_usage <- res_usage[1,1]
fn_usage <- res_usage[1,2]
vn_usage <- res_usage[2,2]
print(paste("Accuracy = ", (vn_usage + vp_usage) / dim(test)[1] ))
print(paste("Recall = ", vp_usage / (vp_usage + fn_usage)))
print(paste("Precision = ", vp_usage / (vp_usage + fp_usage)))
train_clean <- na.omit(train[ , c(socio_pro, "cluster_ind")])
train_control <- trainControl(method = "cv", number = 10)
cp_values <- seq(0.001, 0.05, by = 0.005)
maxdepth_values <- c(2, 3, 4, 5, 6)
results <- data.frame(cp = numeric(), maxdepth = numeric(), Accuracy = numeric())
criteria <- c("gini", "information")
for (criterion in criteria) {
for (cp in cp_values) {
for (maxdepth in maxdepth_values) {
# Entraîner le modèle
model <- rpart(cluster_ind~.,
data = train_clean,
parms = list(split = criterion),
control = rpart.control(cp = cp, maxdepth = maxdepth))
# Prédire sur les données d'entraînement (ou validation croisée si disponible)
predictions <- predict(model, train_clean, type = "class")
# Calculer la précision (ou une autre métrique)
accuracy <- sum(predictions == train_clean$cluster_ind) / nrow(train_clean)
# Stocker les résultats
results <- rbind(results, data.frame(cp = cp, maxdepth = maxdepth, criterion = criterion, Accuracy = accuracy))
}
}
}
best_result <- results[which.max(results$Accuracy), ]
print(best_result)
arbre_usage = rpart(cluster_ind~., data = train[ , c(usage, "cluster_ind")], parms = list(split = criterion), control = list(cp = 0.001, maxdepth = 6))
rpart.plot(arbre_usage)
res_usage <- table(predict(arbre_usage, newdata = test[, c(usage, "cluster_ind")], type = "class"), test$cluster_ind)
res_usage
fp_usage <- res_usage[2,1]
vp_usage <- res_usage[1,1]
fn_usage <- res_usage[1,2]
vn_usage <- res_usage[2,2]
print(paste("Accuracy = ", (vn_usage + vp_usage) / dim(test)[1] ))
print(paste("Recall = ", vp_usage / (vp_usage + fn_usage)))
print(paste("Precision = ", vp_usage / (vp_usage + fp_usage)))
arbre_usage = rpart(cluster_ind~., data = train[ , c(usage, "cluster_ind")], parms = list(split = "gini"), control = list(cp = 0.001, maxdepth = 6))
rpart.plot(arbre_usage)
res_usage <- table(predict(arbre_usage, newdata = test[, c(usage, "cluster_ind")], type = "class"), test$cluster_ind)
res_usage
fp_usage <- res_usage[2,1]
vp_usage <- res_usage[1,1]
fn_usage <- res_usage[1,2]
vn_usage <- res_usage[2,2]
print(paste("Accuracy = ", (vn_usage + vp_usage) / dim(test)[1] ))
print(paste("Recall = ", vp_usage / (vp_usage + fn_usage)))
print(paste("Precision = ", vp_usage / (vp_usage + fp_usage)))
arbre_sp = rpart(cluster_ind~., data = train[ , c(socio_pro, "cluster_ind")], parms = list(split = "gini"), control = list(cp = 0.001, maxdepth = 6))
# cp = critère de complexité du modèle
# maxdepth = profondeur max de l'arbre
rpart.plot(arbre_sp)
res_sp = table(predict(arbre_sp, newdata = test[, c(socio_pro, "cluster_ind")], type = "class"), test$cluster_ind)
res_sp
fp_sp <- res_sp[2,1]
vp_sp <- res_sp[1,1]
fn_sp <- res_sp[1,2]
vn_sp <- res_sp[2,2]
print(paste("Accuracy = ", (vn_sp + vp_sp) / dim(test)[1] ))
print(paste("Recall = ", vp_sp / (vp_sp + fn_sp)))
print(paste("Precision = ", vp_sp / (vp_sp + fp_sp)))
rpart.plot(arbre_sp)
View(arbre_sp)
rpart.plot(arbre_sp, fallen.leaves = FALSE)
rpart.plot(arbre_sp, fallen.leaves = FALSE)
rpart.plot(arbre_sp, fallen.leaves = FALSE)
rpart.rules(arbre_sp)
arbre_sp = rpart(cluster_ind~., data = train[ , c(socio_pro, "cluster_ind")], parms = list(split = "gini"), control = list(cp = 0.001, maxdepth = 6), type = "class")
arbre_sp = rpart(cluster_ind~., data = train[ , c(socio_pro, "cluster_ind")], parms = list(split = "gini"), control = list(cp = 0.001, maxdepth = 6))
# cp = critère de complexité du modèle
# maxdepth = profondeur max de l'arbre
rpart.plot(arbre_sp, fallen.leaves = FALSE)
rpart.rules(arbre_sp)
rpart.plot(arbre_sp, branch = .3, fallen.leaves = FALSE)
rpart.rules(arbre_sp)
rpart.plot(arbre_sp, fallen.leaves = FALSE, under = TRUE)
rpart.rules(arbre_sp)
rpart.plot(arbre_sp, type = 3, fallen.leaves = FALSE, under = TRUE)
rpart.rules(arbre_sp)
rpart.plot(arbre_sp, type = 3, clip.right.labs = FALSE, branch = .3, fallen.leaves = FALSE, under = TRUE)
rpart.rules(arbre_sp)
rpart.plot(arbre_sp, type = 3, clip.right.labs = FALSE, branch = .3, fallen.leaves = FALSE, under = TRUE)
arbre_sp = rpart(cluster_ind~., data = train[ , c(socio_pro, "cluster_ind")], parms = list(split = "gini"), control = list(cp = 0.001, maxdepth = 2))
# cp = critère de complexité du modèle
# maxdepth = profondeur max de l'arbre
rpart.plot(arbre_sp, type = 3, clip.right.labs = FALSE, branch = .3, fallen.leaves = FALSE, under = TRUE)
rpart.rules(arbre_sp)
arbre_sp = rpart(cluster_ind~., data = train[ , c(socio_pro, "cluster_ind")], parms = list(split = "gini"), control = list(cp = 0.001, maxdepth = 6))
# cp = critère de complexité du modèle
# maxdepth = profondeur max de l'arbre
rpart.plot(arbre_sp, type = 3, clip.right.labs = FALSE, branch = .3, fallen.leaves = FALSE, under = TRUE)
rpart.rules(arbre_sp)
pruned_tree <- prune(arbre_sp, cp = arbre_sp$cptable[which(arbre_sp$frame$var == "<leaf>" & arbre_sp$frame$depth <=3), "CP"])
rpart.plot(pruned_tree, type = 3, clip.right.labs = FALSE, branch = .3, fallen.leaves = FALSE, under = TRUE)
rpart.rules(arbre_sp)
pruned_tree <- prune(arbre_sp, cp = arbre_sp$cptable[which(arbre_sp$frame$var == "<leaf>" & arbre_sp$frame$depth <=3), "CP"])
rpart.plot(pruned_tree)
rpart.rules(arbre_sp)
pruned_tree <- prune(arbre_sp, cp = arbre_sp$cptable[which(arbre_sp$frame$var == "<leaf>" & arbre_sp$frame$depth <=3), "CP"])
rpart.plot(pruned_tree, type = 3, clip.right.labs = FALSE, branch = .3, fallen.leaves = FALSE, under = TRUE)
rpart.rules(arbre_sp)
rpart.plot(arbre_sp, type = 3, clip.right.labs = FALSE, branch = .3, fallen.leaves = FALSE, under = TRUE)
rpart.rules(arbre_sp)
rpart.plot(arbre_sp, type = 3, clip.right.labs = FALSE, branch = .3, fallen.leaves = FALSE, under = TRUE)
rpart.plot(arbre_sp, type = 3, clip.right.labs = FALSE, branch = .3, fallen.leaves = FALSE, under = TRUE, cex = 12)
rpart.rules(arbre_sp)
rpart.plot(arbre_sp, type = 3, clip.right.labs = FALSE, branch = .3, fallen.leaves = FALSE, under = TRUE, cex = 1)
rpart.rules(arbre_sp)
rpart.plot(arbre_sp, type = 3, clip.right.labs = FALSE, branch = .3, fallen.leaves = FALSE, under = TRUE, cex = 0.1)
rpart.rules(arbre_sp)
rpart.plot(arbre_sp, type = 3, clip.right.labs = FALSE, branch = .3, fallen.leaves = FALSE, under = TRUE, cex = 0.5)
rpart.rules(arbre_sp)
rpart.plot(arbre_sp, type = 3, clip.right.labs = FALSE, branch = .3, fallen.leaves = FALSE, under = TRUE, cex = 0.25)
rpart.rules(arbre_sp)
rpart.plot(arbre_sp, type = 3, clip.right.labs = FALSE, branch = .3, fallen.leaves = FALSE, under = TRUE, cex = 0.35)
rpart.rules(arbre_sp)
rpart.plot(arbre_sp, type = 3, clip.right.labs = FALSE, branch = .3, fallen.leaves = FALSE, under = TRUE, cex = 0.35)
rpart.plot(arbre_sp, type = 3, clip.right.labs = FALSE, branch = .3, fallen.leaves = FALSE, under = TRUE, cex = 0.5)
rpart.plot(arbre_sp, type = 3,  fallen.leaves = FALSE, under = TRUE, cex = 0.5)
rpart.rules(arbre_sp)
rpart.plot(arbre_sp, type = 3, clip.right.labs = FALSE, fallen.leaves = FALSE, under = TRUE, cex = 0.5)
rpart.rules(arbre_sp)
rpart.plot(arbre_sp, type = 3, clip.right.labs = FALSE, fallen.leaves = FALSE, under = TRUE, cex = 0.5)
rpart.plot(arbre_sp, type = 3, clip.right.labs = T, fallen.leaves = FALSE, under = TRUE, cex = 0.5)
rpart.plot(arbre_sp, type = 1, clip.right.labs = TRUE, fallen.leaves = FALSE, under = TRUE, cex = 0.5)
rpart.plot(arbre_sp, type = 2, clip.right.labs = TRUE, fallen.leaves = FALSE, under = TRUE, cex = 0.5)
rpart.plot(arbre_sp, type = 4, clip.right.labs = TRUE, fallen.leaves = FALSE, under = TRUE, cex = 0.5)
rpart.plot(arbre_sp, type = 5, clip.right.labs = TRUE, fallen.leaves = FALSE, under = TRUE, cex = 0.5)
rpart.plot(arbre_sp, type = 6, clip.right.labs = TRUE, fallen.leaves = FALSE, under = TRUE, cex = 0.5)
rpart.plot(arbre_sp, type = 3, clip.right.labs = TRUE, fallen.leaves = FALSE, under = TRUE, cex = 0.5)
rpart.rules(arbre_sp)
rpart.plot(arbre_sp, type = 3, clip.right.labs = TRUE, fallen.leaves = FALSE, under = TRUE, cex = 0.5)
rpart.rules(arbre_sp)
rpart.plot(arbre_usage, type = 3, clip.right.labs = TRUE, fallen.leaves = FALSE, under = TRUE, cex = 0.5)
rpart.rules(arbre_usage)
rpart.plot(arbre_usage, type = 3, clip.right.labs = TRUE, fallen.leaves = FALSE, under = TRUE, cex = 0.5)
